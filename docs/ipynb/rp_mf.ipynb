{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autorec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configurations\n",
    "First, handle the imports with the correct configurations set. Also include the logging settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import tensorflow as tf\n",
    "# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# import tensorflow as tf\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import logging\n",
    "from autorecsys.auto_search import Search\n",
    "from autorecsys.pipeline import Input, LatentFactorMapper, RatingPredictionOptimizer, ElementwiseInteraction\n",
    "from autorecsys.pipeline.preprocessor import MovielensPreprocessor, NetflixPrizePreprocessor\n",
    "from autorecsys.recommender import RPRecommender\n",
    "\n",
    "# logging setting\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "Load the dataset, which in this case is set to the Movielens 1 million dataset, although options exist for a 10 million, latest, and Netflix dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "##Netflix Dataset\n",
    "# dataset_paths = [\"./examples/datasets/netflix-prize-data/combined_data_\" + str(i) + \".txt\" for i in range(1, 5)]\n",
    "# data = NetflixPrizePreprocessor(dataset_paths)\n",
    "\n",
    "#Movielens 1M Dataset\n",
    "data = MovielensPreprocessor(\"./examples/datasets/ml-1m/ratings.dat\")\n",
    "\n",
    "##Movielens 10M Dataset\n",
    "# data = MovielensPreprocessor(\"./examples/datasets/ml-10M100K/ratings.dat\")\n",
    "\n",
    "##Movielens latest Dataset\n",
    "# data = MovielensPreprocessor(\"./examples/datasets/ml-latest/ratings.csv\", sep=',')\n",
    "\n",
    "data.preprocessing(val_test_size=0.1, random_state=1314)\n",
    "train_X, train_y = data.train_X, data.train_y\n",
    "val_X, val_y = data.val_X, data.val_y\n",
    "test_X, test_y = data.test_X, data.test_y\n",
    "user_num, item_num = data.user_num, data.item_num\n",
    "logger.info('train_X size: {}'.format(train_X.shape))\n",
    "logger.info('train_y size: {}'.format(train_y.shape))\n",
    "logger.info('val_X size: {}'.format(val_X.shape))\n",
    "logger.info('val_y size: {}'.format(val_y.shape))\n",
    "logger.info('test_X size: {}'.format(test_X.shape))\n",
    "logger.info('test_y size: {}'.format(test_y.shape))\n",
    "logger.info('user total number: {}'.format(user_num))\n",
    "logger.info('item total number: {}'.format(item_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline\n",
    "Creates the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the pipeline.\n",
    "input = Input(shape=[2])\n",
    "user_emb = LatentFactorMapper(feat_column_id=0,\n",
    "                              id_num=user_num,\n",
    "                              embedding_dim=64)(input)\n",
    "item_emb = LatentFactorMapper(feat_column_id=1,\n",
    "                              id_num=item_num,\n",
    "                              embedding_dim=64)(input)\n",
    "output = ElementwiseInteraction(elementwise_type=\"innerporduct\")([user_emb, item_emb])\n",
    "output = RatingPredictionOptimizer()(output)\n",
    "model = RPRecommender(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the search and predict\n",
    "The searcher goes through the model and makes a prediction. At the end, the model is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML search and predict\n",
    "searcher = Search(model=model,\n",
    "                  tuner='greedy',  # hyperband, greedy, bayesian\n",
    "                  tuner_params={\"max_trials\": 5}\n",
    "                  )\n",
    "\n",
    "searcher.search(x=train_X,\n",
    "                y=train_y,\n",
    "                x_val=val_X,\n",
    "                y_val=val_y,\n",
    "                objective='val_mse',\n",
    "                batch_size=1024,\n",
    "                epochs=10,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)])\n",
    "logger.info('Predicting Val Dataset Accuracy (mse): {}'.format(searcher.evaluate(x=val_X, y_true=val_y)))\n",
    "logger.info('Predicting Test Dataset Accuracy (mse): {}'.format(searcher.evaluate(x=test_X, y_true=test_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

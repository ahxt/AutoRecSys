{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autorec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configurations\n",
    "First, handle the imports with the correct configurations set. Also include the logging settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from autorecsys.auto_search import Search\n",
    "from autorecsys.pipeline import Input, LatentFactorMapper, RatingPredictionOptimizer, HyperInteraction\n",
    "from autorecsys.pipeline.preprocessor import MovielensPreprocessor\n",
    "from autorecsys.recommender import RPRecommender\n",
    "\n",
    "# logging setting\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "The next step is to load in the movie lens data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = MovielensPreprocessor()\n",
    "train_X, train_y, val_X, val_y, test_X, test_y = movielens.preprocess()\n",
    "train_X_categorical = movielens.get_x_categorical(train_X)\n",
    "val_X_categorical = movielens.get_x_categorical(val_X)\n",
    "test_X_categorical = movielens.get_x_categorical(test_X)\n",
    "user_num, item_num = movielens.get_hash_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the recommender\n",
    "After loading the data, set up mappers, interactors, and optimizers. This builds the search space and handles the inputs to help generate the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Setup mappers to handle inputs\n",
    "input = Input(shape=[2])\n",
    "user_emb = LatentFactorMapper(feat_column_id=0,\n",
    "                              id_num=user_num,\n",
    "                              embedding_dim=64)(input)\n",
    "item_emb = LatentFactorMapper(feat_column_id=1,\n",
    "                              id_num=item_num,\n",
    "                              embedding_dim=64)(input)\n",
    "\n",
    "# Step 2.2: Setup interactors to handle models\n",
    "output1 = HyperInteraction()([user_emb, item_emb])\n",
    "output2 = HyperInteraction()([output1, user_emb, item_emb])\n",
    "output3 = HyperInteraction()([output1, output2, user_emb, item_emb])\n",
    "output4 = HyperInteraction()([output1, output2, output3, user_emb, item_emb])\n",
    "\n",
    "# Step 2.3: Setup optimizer to handle the target task\n",
    "output = RatingPredictionOptimizer()(output4)\n",
    "model = RPRecommender(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the searcher\n",
    "Once the recommender is complete, we build the searcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = Search(model=model,\n",
    "                  tuner='random',\n",
    "                  tuner_params={'max_trials': 2, 'overwrite': True},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the searcher\n",
    "We use the searcher to dig through our recommender's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.search(x=[train_X_categorical],\n",
    "                y=train_y,\n",
    "                x_val=[val_X_categorical],\n",
    "                y_val=val_y,\n",
    "                objective='val_mse',\n",
    "                batch_size=1024,\n",
    "                epochs=1,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)])\n",
    "logger.info('Validation Accuracy (mse): {}'.format(searcher.evaluate(x=val_X_categorical,\n",
    "                                                                     y_true=val_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "This is to review the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Test Accuracy (mse): {}'.format(searcher.evaluate(x=test_X_categorical,\n",
    "                                                               y_true=test_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

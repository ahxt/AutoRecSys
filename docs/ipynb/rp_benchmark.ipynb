{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autorec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configurations\n",
    "First, handle the imports with the correct configurations set. Also include the logging settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import logging\n",
    "# logging setting\n",
    "logging.basicConfig(stream=sys.stdout,\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from autorecsys.auto_search import Search\n",
    "from autorecsys.pipeline import Input, LatentFactorMapper, RatingPredictionOptimizer, HyperInteraction, MLPInteraction, \\\n",
    "    ElementwiseInteraction\n",
    "from autorecsys.pipeline.preprocessor import MovielensPreprocessor, NetflixPrizePreprocessor\n",
    "from autorecsys.recommender import RPRecommender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models\n",
    "Next, we create the models that the AutoRec system will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mf(user_num, item_num):\n",
    "    input = Input(shape=[2])\n",
    "    user_emb = LatentFactorMapper(feat_column_id=0,\n",
    "                                  id_num=user_num,\n",
    "                                  embedding_dim=64)(input)\n",
    "    item_emb = LatentFactorMapper(feat_column_id=1,\n",
    "                                  id_num=item_num,\n",
    "                                  embedding_dim=64)(input)\n",
    "    output = ElementwiseInteraction(elementwise_type=\"innerporduct\")([user_emb, item_emb])\n",
    "    output = RatingPredictionOptimizer()(output)\n",
    "    model = RPRecommender(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_gmf(user_num, item_num):\n",
    "    input = Input(shape=[2])\n",
    "    user_emb = LatentFactorMapper(feat_column_id=0,\n",
    "                                  id_num=user_num,\n",
    "                                  embedding_dim=64)(input)\n",
    "    item_emb = LatentFactorMapper(feat_column_id=1,\n",
    "                                  id_num=item_num,\n",
    "                                  embedding_dim=64)(input)\n",
    "    output = ElementwiseInteraction(elementwise_type=\"innerporduct\")([user_emb, item_emb])\n",
    "    output = RatingPredictionOptimizer()(output)\n",
    "    model = RPRecommender(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_mlp(user_num, item_num):\n",
    "    input = Input(shape=[2])\n",
    "    user_emb_mlp = LatentFactorMapper(feat_column_id=0,\n",
    "                                      id_num=user_num,\n",
    "                                      embedding_dim=64)(input)\n",
    "    item_emb_mlp = LatentFactorMapper(feat_column_id=1,\n",
    "                                      id_num=user_num,\n",
    "                                      embedding_dim=64)(input)\n",
    "    output = MLPInteraction()([user_emb_mlp, item_emb_mlp])\n",
    "    output = RatingPredictionOptimizer()(output)\n",
    "    model = RPRecommender(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_neumf(user_num, item_num):\n",
    "    input = Input(shape=[2])\n",
    "    user_emb_gmf = LatentFactorMapper(feat_column_id=0,\n",
    "                                      id_num=user_num,\n",
    "                                      embedding_dim=64)(input)\n",
    "    item_emb_gmf = LatentFactorMapper(feat_column_id=1,\n",
    "                                      id_num=item_num,\n",
    "                                      embedding_dim=64)(input)\n",
    "    innerproduct_output = ElementwiseInteraction(elementwise_type=\"innerporduct\")([user_emb_gmf, item_emb_gmf])\n",
    "\n",
    "    user_emb_mlp = LatentFactorMapper(feat_column_id=0,\n",
    "                                      id_num=user_num,\n",
    "                                      embedding_dim=64)(input)\n",
    "    item_emb_mlp = LatentFactorMapper(feat_column_id=1,\n",
    "                                      id_num=item_num,\n",
    "                                      embedding_dim=64)(input)\n",
    "    mlp_output = MLPInteraction()([user_emb_mlp, item_emb_mlp])\n",
    "\n",
    "    output = RatingPredictionOptimizer()([innerproduct_output, mlp_output])\n",
    "    model = RPRecommender(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_autorec(user_num, item_num):\n",
    "    input = Input(shape=[2])\n",
    "    user_emb_1 = LatentFactorMapper(feat_column_id=0,\n",
    "                                    id_num=user_num,\n",
    "                                    embedding_dim=64)(input)\n",
    "    item_emb_1 = LatentFactorMapper(feat_column_id=1,\n",
    "                                    id_num=item_num,\n",
    "                                    embedding_dim=64)(input)\n",
    "\n",
    "    user_emb_2 = LatentFactorMapper(feat_column_id=0,\n",
    "                                    id_num=user_num,\n",
    "                                    embedding_dim=64)(input)\n",
    "    item_emb_2 = LatentFactorMapper(feat_column_id=1,\n",
    "                                    id_num=item_num,\n",
    "                                    embedding_dim=64)(input)\n",
    "\n",
    "    output = HyperInteraction()([user_emb_1, item_emb_1, user_emb_2, item_emb_2])\n",
    "    output = RatingPredictionOptimizer()(output)\n",
    "    model = RPRecommender(inputs=input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main argument\n",
    "Runs in the main fuction, which parases the arguments, loads the dataset, then buildsand searches the desired model based on user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # parse args\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-model', type=str, help='input a model name')\n",
    "    parser.add_argument('-data', type=str, help='dataset name')\n",
    "    parser.add_argument('-data_path', type=str, help='dataset path')\n",
    "    parser.add_argument('-sep', type=str, help='dataset sep')\n",
    "    parser.add_argument('-search', type=str, help='input a search method name')\n",
    "    parser.add_argument('-batch_size', type=int, help='batch size')\n",
    "    parser.add_argument('-epochs', type=int, help='epochs')\n",
    "    parser.add_argument('-early_stop', type=int, help='early stop')\n",
    "    parser.add_argument('-trials', type=int, help='try number')\n",
    "    args = parser.parse_args()\n",
    "    # print(\"args:\", args)\n",
    "    if args.sep == None:\n",
    "        args.sep = '::'\n",
    "\n",
    "    # Load dataset\n",
    "    if args.data == \"ml\":\n",
    "        data = MovielensPreprocessor(args.data_path, sep=args.sep)\n",
    "    if args.data == \"netflix\":\n",
    "        dataset_paths = [args.data_path + \"/combined_data_\" + str(i) + \".txt\" for i in range(1, 5)]\n",
    "        data = NetflixPrizePreprocessor(dataset_paths)\n",
    "    data.preprocessing(val_test_size=0.1, random_state=1314)\n",
    "    train_X, train_y = data.train_X, data.train_y\n",
    "    val_X, val_y = data.val_X, data.val_y\n",
    "    test_X, test_y = data.test_X, data.test_y\n",
    "    user_num, item_num = data.user_num, data.item_num\n",
    "    logging.info('train_X size: {}'.format(train_X.shape))\n",
    "    logging.info('train_y size: {}'.format(train_y.shape))\n",
    "    logging.info('val_X size: {}'.format(val_X.shape))\n",
    "    logging.info('val_y size: {}'.format(val_y.shape))\n",
    "    logging.info('test_X size: {}'.format(test_X.shape))\n",
    "    logging.info('test_y size: {}'.format(test_y.shape))\n",
    "    logging.info('user total number: {}'.format(user_num))\n",
    "    logging.info('item total number: {}'.format(item_num))\n",
    "\n",
    "    # select model\n",
    "    if args.model == 'mf':\n",
    "        model = build_mf(user_num, item_num)\n",
    "    if args.model == 'mlp':\n",
    "        model = build_mlp(user_num, item_num)\n",
    "    if args.model == 'gmf':\n",
    "        model = build_gmf(user_num, item_num)\n",
    "    if args.model == 'neumf':\n",
    "        model = build_neumf(user_num, item_num)\n",
    "    if args.model == 'autorec':\n",
    "        model = build_autorec(user_num, item_num)\n",
    "\n",
    "    # search and predict.\n",
    "    searcher = Search(model=model,\n",
    "                      tuner=args.search,  ## hyperband, bayesian\n",
    "                      tuner_params={'max_trials': args.trials, 'overwrite': True}\n",
    "                      )\n",
    "\n",
    "    start_time = time.time()\n",
    "    searcher.search(x=train_X,\n",
    "                    y=train_y,\n",
    "                    x_val=val_X,\n",
    "                    y_val=val_y,\n",
    "                    objective='val_mse',\n",
    "                    batch_size=args.batch_size,\n",
    "                    epochs=args.epochs,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=args.early_stop)])\n",
    "    end_time = time.time()\n",
    "    # print(\"Runing time:\", end_time - start_time)\n",
    "    # print(\"Args\", args)\n",
    "    logging.info('Runing time: {}'.format(end_time - start_time))\n",
    "    logging.info('Args: {}'.format(args))\n",
    "    logging.info('Predicting Val Dataset Accuracy (mse): {}'.format(searcher.evaluate(x=val_X, y_true=val_y)))\n",
    "    logging.info('Predicting Test Dataset Accuracy (mse): {}'.format(searcher.evaluate(x=test_X, y_true=test_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
